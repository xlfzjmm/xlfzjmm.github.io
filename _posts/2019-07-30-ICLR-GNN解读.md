---
layout:     post   				    # 使用的布局（不需要改）
title:      Graph Neural Networks Meet Personalized PageRank解读与思考 				# 标题
date:       2019-07-30 				# 时间
author:     fxl 						# 作者
header-img: img/bg15.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 论文笔记
---

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

# 摘要
本文发表在ICLR 2019上面，作者来自于德国慕尼黑工业大学。作者首先分析了基于消息传递框架的图卷积神经网络存在的问题及局限性，进一步地提出利用Personalized PageRank来增强流行的图神经网络的Propagation过程。 

# Graph Convolutional存在的问题
## Graph Convolutional Networks
对于图 \\(G = (V, E)\\), 有 \\( \tilde{A} = A + I_n\\)。一般而言，GCN通常采用两层的结构，即：

$$ Z_{GCN} = softmax( \hat{\tilde{A}} ReLu(\hat{\tilde{A}}X W_0)W_1) $$

其中 \\(  \hat{\tilde{A}} = \tilde{D}^{-\frac{1}{2}} \tilde{A} \tilde{D}^{-\frac{1}{2}} \\)。 对于图神经网络，首先，平均聚合的方式会带来过平滑问题，因此常用的图神经网络只关注局部的邻域。其次，网络越深能够带来能好的拟合效果和更加全局的特征对于某些节点。可以看到，参与计算的邻域数量与网络的深度是正交的。

## 从Random Walk出发探索GNN局限性
从[Jumping Knowledge Networks](https://arxiv.org/abs/1806.03536)已知，K层的GCN相当于从源节点x出发到y的一个K步的Random Walk，取\\(k\to\infty\\), 节点的极限分布与初始的节点表示无关，只与图拓扑相关 （类似于马尔可夫模型，极限状态与初始分布无关。显然，当前的GNN模式并不适合描述节点的表示。

# Personalized Propagation

## PPNP算法
为了使节点的极限分布与初始节点有关，考虑采用Personalized PageRank传播模式，





