---
layout:     post   				    # 使用的布局（不需要改）
title:      F1-score与Macro-score、Micro-score计算与理解 				# 标题
date:       2019-08-13 				# 时间
author:     fxl 						# 作者
header-img: img/bg11.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - 技术随笔
---

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
# 基本概念
在理解F1-score之前，首先需要了解一下几个概念，分别为accuracy, precision, recall, 以及TP (true positive), FP (false positive), TN (true negitive), FN (false negitive)。

* TP - 被模型预测为**正**的**正**样本
* FP - 被模型预测为**正**的**负**样本
* TN - 被模型预测为**负**的**负**样本
* FN - 被模型预测为**负**的**正**样本

假设存二分类模型使得模型在测试数据集上的结果如下表所示，横坐标为Ground Truth, 纵坐标为预测值：

|   | 正 | 负 |
|  ----  | ----  | ----  |
| 正 | 0.4（TP） | 0.2 (FP） | 
| 负 | 0.1 (FN) | 0.3 (TN) |

则 $TP = 0.3$, $FP = 0.1$, $TN = 0.4$, $FN = 0.2$。 

# 准确率 - Accuracy
准确率是指，对于给定的测试数据集，分类器正确分类的样本书与总样本数之比，也就是预测正确的概率。即:
$$Accuracy = \frac{TP + FN}{TP + FP + TN + FN}$$
对应上述例子，有$Accuracy = 0.7$。准确率作为我们最常用的指标，当出现样本不均衡的情况时，并不能合理反映模型的预测能力。例如测试数据集有90%的正样本，10%的负样本，假设模型预测结果全为正样本，这时准确率为90%，然而模型对负样本没有识别能力，此时高准确率不能反映模型的预测能力。

# 精确率 - Precision
Precision表示预测为正类中，实际为正类的比例，即：
$$Precision \ (P) = \frac{TP}{TP + FP}$$
对应上述例子，有$P = \frac{0.3}{0.3 + 0.1} = 0.75$。

# 召回率 - Recall
Recall表示实际为正的样本被判断为正样本的比例，即：
$$Recall \ (R) = \frac{TP}{TP + FN}$$
对应上述例子，有$R = \frac{0.3}{0.3 + 0.2} = 0.6$

# F1值 - F1-score

